{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84588a6d-d18e-4ad6-8d06-e251d942fb7c",
   "metadata": {},
   "source": [
    "# [MICRO-452:] Project Report - Groupe 28\n",
    "**Authors:** Celest Angela Tjong, Adrien Louis Baptiste Dupont, Luca Sidoti Pinto, Didier Henri Neuenschwander\n",
    "**Supervisors:** Prof. Francesco Mondada\n",
    "Date: 17 Novembre 2023\n",
    "\n",
    "[MICRO-452]: **to be changed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2258c98-b00d-4caf-a0a6-b64e2262d6e0",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red; font-size:40px;\">use as few personal pronouns as possible (we, our, etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c8421-4f25-49b6-8bc0-f73cc5369cd5",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Introduction](#introduction)\n",
    "* [2. Vision](#vision)\n",
    "    * [2.1. Subsection 1](#vision-subsection-1)\n",
    "    * [2.2. Subsection 2](#vision-subsection-2)\n",
    "* [3. Global Navigation](#global-navigation)\n",
    "* [4. Filtering](#filtering)\n",
    "* [5. Local Navigation](#local-navigation)\n",
    "* [6. Conclusion](#conclusion)\n",
    "lusion)\n",
    "clusion)\n",
    "usion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e09dc-1142-46dd-8485-6bc9b292bf37",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "<a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bfb7cc-aff3-468a-855e-2ef86f760444",
   "metadata": {},
   "source": [
    "## 2 Vision\n",
    "<a id=\"vision\"></a>\n",
    "https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add8a4f-6198-4070-8728-8f1b016321d7",
   "metadata": {},
   "source": [
    "### Vision Subsection 1\n",
    "<a id=\"Vision-subsection-1\"></a>\n",
    "**Ask to TA if we have to describe every function used in the notebook?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffe28c2-e175-40fb-b718-f526a3b25e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy._DTypeMeta' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27512/1321274440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0mbootstrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__collect_extra_submodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0m__load_extra_py_code_for_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cv2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extra Python code for\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m__load_extra_py_code_for_module\u001b[1;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mnative_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpy_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0menable_debug_print\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\typing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumpyVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;34m\"1.20.0\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mNumPyArrayGeneric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mNumPyArrayGeneric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy._DTypeMeta' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "# Define color thresholds in HSV\n",
    "# Note: these thresholds may need to be adjusted for your specific image conditions\n",
    "lower_red_bound = np.array([120, 100, 70])\n",
    "upper_red_bound = np.array([255, 255, 255])\n",
    "lower_green_bound = np.array([60, 50, 100])\n",
    "upper_green_bound = np.array([100, 255, 255])\n",
    "lower_yellow_bound = np.array([0, 30, 120])\n",
    "upper_yellow_bound = np.array([40, 105, 255])\n",
    "lower_black_bound = np.array([0, 0, 0])\n",
    "upper_black_bound = np.array([180, 180, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b67ae3-5774-4f12-9345-9cc499b15b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tdmclient Notebook environment:\n",
    "#import tdmclient.notebook\n",
    "#await tdmclient.notebook.start()\n",
    "# forward\n",
    "#motor_left_target= 100\n",
    "#motor_right_target= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926418ed-c1c2-4aa3-ac23-8f7630815551",
   "metadata": {},
   "source": [
    "Function that record a video and save it on the folder of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1ae44-55a6-49f6-b96a-0854adea57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1080)\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "# Obtenir les dimensions de la frame\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Définir le codec et créer un objet VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Enregistrer la vidéo\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if ret:\n",
    "        # Écrire la frame dans le fichier\n",
    "        out.write(frame)\n",
    "\n",
    "        # Afficher la frame (si vous voulez voir le flux en temps réel)\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        # Quitter avec la touche 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Libérer les ressources\n",
    "video_capture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ca27f-3812-4957-ba8b-73ae4c6c68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to detect circles of a specific color\n",
    "def detect_color_circle(image, lower_color_bound, upper_color_bound):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for the specified color\n",
    "    mask = cv2.inRange(hsv, lower_color_bound, upper_color_bound)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    color_only = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Convert to grayscale for circle detection\n",
    "    gray = cv2.cvtColor(color_only, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Canny edge detection to help with circle detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    # Use Hough Transform to detect circles\n",
    "    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                           param1=20, param2=15, minRadius=10, maxRadius=50)\n",
    "    \n",
    "    # If circles are detected, return the list of circles with x, y coordinates and radius\n",
    "    if circles is not None:\n",
    "        # Convert the (1, N, 3) array to (N, 3)\n",
    "        circles = np.uint16(np.around(circles[0, :]))          \n",
    "        return [(circle[0], circle[1], circle[2]) for circle in circles]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4f67d-21ce-4785-a6f9-de19714850bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_obstacle_mask(image, contours, kernel_size):\n",
    "    \"\"\"\n",
    "    Create a mask with zeros in the areas inside the dilated contours.\n",
    "\n",
    "    :param image: Input image.\n",
    "    :param contours: Contours to dilate and fill in the mask.\n",
    "    :param kernel_size: Size of the kernel used for dilation.\n",
    "    :return: Mask with zeros inside the dilated contours and ones elsewhere.\n",
    "    \"\"\"\n",
    "    # Create an empty mask of the same size as the image\n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.ones((h, w), dtype=np.uint8)\n",
    "\n",
    "    # Perform dilation to increase the size of the black regions\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    for contour in contours:\n",
    "        # Create an individual mask for each contour\n",
    "        contour_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        cv2.fillPoly(contour_mask, [contour], 255)\n",
    "        contour_mask = cv2.dilate(contour_mask, kernel, iterations=1)\n",
    "        \n",
    "        # Combine the individual mask with the global mask\n",
    "        mask = cv2.bitwise_and(mask, cv2.bitwise_not(contour_mask))\n",
    "\n",
    "        #also add the contours\n",
    "        # Let's create a border around the image\n",
    "        border_size = 50\n",
    "        border_color = [0, 0, 0]  # Black border\n",
    "        # Use cv2.copyMakeBorder to add a border around the image\n",
    "        mask_with_border = cv2.copyMakeBorder(mask, border_size, border_size, border_size, border_size,\n",
    "                                           cv2.BORDER_CONSTANT, value=border_color)\n",
    "    \n",
    "    return mask_with_border\n",
    "\n",
    "\n",
    "# Now you have a mask with zeros in the obstacle areas and ones elsewhere\n",
    "# You can return this mask from your function or process it further as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151aada-0dc7-4d3d-9514-dbfca0ad35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_obstacle_contours(image, area_threshold, kernel_size):\n",
    "    \"\"\"\n",
    "    Detects and dilates obstacle contours in the given image.\n",
    "    :param image: Input image.\n",
    "    :param area_threshold: Area threshold for filtering contours.\n",
    "    :param kernel_size: Size of the kernel used for dilation.\n",
    "    :return: Image with obstacle contours drawn.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask_black = cv2.inRange(hsv, lower_black_bound, upper_black_bound)\n",
    "    contours, _ = cv2.findContours(mask_black, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > area_threshold]\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    mask_dilated = cv2.dilate(mask_black, kernel, iterations=1)\n",
    "    dilated_contours, _ = cv2.findContours(mask_dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_dilated_contours = [cnt for cnt in dilated_contours if cv2.contourArea(cnt) > area_threshold+1000]\n",
    "    contour_image = image.copy()\n",
    "    cv2.drawContours(contour_image, filtered_contours, -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(contour_image, filtered_dilated_contours, -1, (0, 0, 255), 2)\n",
    "    return contour_image, filtered_contours, filtered_dilated_contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13047d64-3da8-4f07-b297-a7fd8fc28292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obstacle_matrix(image, dilated_contours):\n",
    "    height, width = image.shape[:2]\n",
    "    obstacle_matrix = np.ones((height, width), dtype=np.uint8)\n",
    "\n",
    "    for contour in dilated_contours:\n",
    "        # Remplir chaque contour dilaté avec 0 (obstacle)\n",
    "        cv2.fillPoly(obstacle_matrix, [contour], 0)\n",
    "\n",
    "    return obstacle_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f0da7-ba21-4f7f-8161-3b76a6e77880",
   "metadata": {},
   "source": [
    "In each frame, there are multiple elements that need to be displayed. The first category includes static elements such as the contours of obstacles and the goal point. Since these do not change over time, it is computationally more efficient to identify and locate them in the first frame, and then display them consistently in subsequent frames.\n",
    "\n",
    "On the other hand, elements related to the robot's localization must be determined in each frame. To gather information about its orientation and location, three circles are placed on the top of the robot. A green circle is located at the middle back, and two red circles are positioned on each side, with their centers aligned with the robot's ceeris. This arrangement facilitates the extraction of necessary information. By connecting the centers of the two red circles and creating a midpoint, a vector c thenan be formed by connecting this midpoint to the center of the green circ.It might also be feasible to use only two markers (circles), one at the back and one at the front, distinguished by their color. However, the marker at the front would hide the press button.le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c51b5c-0df7-4528-99d5-a5e367371f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chemin du fichier vidéo enregistré\n",
    "video_path = 'output.avi'\n",
    "\n",
    "# Ouvrir le fichier vidéo\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Assurez-vous que le fichier vidéo s'ouvre correctement\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Erreur : Impossible d'ouvrir le fichier vidéo.\")\n",
    "    exit()\n",
    "#video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1080)\n",
    "video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "window_name = 'Robot Detection'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Redimensionner la fenêtre (largeur, hauteur)\n",
    "cv2.resizeWindow(window_name, 540, 360)  # Réduire de moitié par exemple\n",
    "\n",
    "# Initial detection of obstacles\n",
    "ret, initial_frame = video_capture.read()\n",
    "if ret:\n",
    "     contour_image = detect_obstacle_contours(initial_frame, 2000, 70)\n",
    "     global_obstacle = create_obstacle_matrix(initial_frame, contour_image[2])\n",
    "     plt.imshow(cv2.cvtColor(contour_image[0], cv2.COLOR_BGR2RGB))\n",
    "     plt.title('Initial Contours')\n",
    "     plt.axis('off')\n",
    "     plt.show()\n",
    "     yellow_circles = detect_color_circle(initial_frame, lower_yellow_bound, upper_yellow_bound)\n",
    "     if yellow_circles:\n",
    "    # Stocker les coordonnées du premier cercle jaune détecté\n",
    "        yellow_circle_coords = yellow_circles[0]\n",
    "\n",
    "# Robot update frequency (10 Hz)\n",
    "update_rate = 0.1  # 10 times per second\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Mettre à jour les contours d'obstacle pour la frame actuelle\n",
    " \n",
    "        # Detect red and green circles\n",
    "        red_circles = detect_color_circle(frame, lower_red_bound, upper_red_bound)\n",
    "        green_circles = detect_color_circle(frame, lower_green_bound, upper_green_bound)\n",
    "\n",
    "\n",
    "        \n",
    "        if yellow_circles:\n",
    "            x, y, r = yellow_circles[0] #coordinate of the goal*********************************************************\n",
    "            cv2.circle(frame, (x, y), r, (0, 255, 255), 3) # Dessiner les cercles jaunes\n",
    "\n",
    "            \n",
    "        if red_circles and green_circles:\n",
    "                    if len(red_circles) >= 2:\n",
    "                        # Calculate the midpoint between the centers of the red circles\n",
    "                        midpoint = ((red_circles[0][0] + red_circles[1][0]) // 2,\n",
    "                        (red_circles[0][1] + red_circles[1][1]) // 2)\n",
    "                        # Calculer le vecteur directionnel\n",
    "                        direction = np.array([midpoint[0] - green_circles[0][0], midpoint[1] - green_circles[0][1]])\n",
    "                    \n",
    "                        # Normaliser et allonger le vecteur\n",
    "                        length = 100  # Longueur supplémentaire\n",
    "                        direction = direction / np.linalg.norm(direction) * length\n",
    "                    \n",
    "                        # Calculer le nouveau point d'arrivée\n",
    "                        new_endpoint = (int(green_circles[0][0] + direction[0]), int(green_circles[0][1] + direction[1]))\n",
    "                    \n",
    "                        # Dessiner la flèche allongée\n",
    "                        cv2.arrowedLine(frame, green_circles[0][:2], new_endpoint, (0, 0, 0), 3)\n",
    "\n",
    "                        # Calculate the angle of orientation with respect to the x-axis\n",
    "                        dx = green_circles[0][0] - midpoint[0]\n",
    "                        dy = green_circles[0][1] - midpoint[1]\n",
    "                        angle = math.atan2(dy, dx)\n",
    "                        angle_degrees = math.degrees(angle)\n",
    "                        robot_vector = (midpoint[0], midpoint[1], angle_degrees) #information of the robot\n",
    "                        # Optionally, display the angle\n",
    "                        cv2.putText(frame, f'Angle: {angle_degrees:.2f} degrees', (10, 30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                     \n",
    "                        cv2.putText(frame, f'Midpoint: ({midpoint[0]}, {midpoint[1]})', (10, 700),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            \n",
    "        cv2.drawContours(frame, contour_image[1], -1, (0, 255, 0), 2)\n",
    "        cv2.drawContours(frame, contour_image[2], -1, (0, 0, 255), 2)\n",
    "        # Dimensions de la frame\n",
    "\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Coordonnées du point de départ du repère (bas droit de l'image)\n",
    "        origin_x, origin_y = width - 150, height - 70  # Ajustement pour une longueur de 100\n",
    "        # Dessiner l'axe X\n",
    "        cv2.line(frame, (origin_x, origin_y), (origin_x + 100, origin_y), (0, 0, 255), 2)\n",
    "        # Dessiner l'axe Y \n",
    "        cv2.line(frame, (origin_x, origin_y), (origin_x, origin_y - 100), (0, 255, 0), 2)\n",
    "        # Marquer la longueur sur l'axe X\n",
    "        cv2.putText(frame, \"100\", (origin_x + 100, origin_y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)\n",
    "        # Marquer la longueur sur l'axe Y\n",
    "        cv2.putText(frame, \"100\", (origin_x - 30, origin_y - 100), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 2)\n",
    "        cv2.putText(frame, f'({origin_x}, {origin_y})', (origin_x-200, origin_y-10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2) #environ 14cm pour 100pixcel\n",
    "        # ... (le reste de votre code pour afficher la frame)\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Robot Detection', frame)\n",
    "\n",
    "        # Pause to maintain the update frequency\n",
    "        time_to_wait = max(int((start_time + update_rate - time.time()) * 1000), 1)\n",
    "        if cv2.waitKey(time_to_wait) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    # Release the capture when everything is finished\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec623cd9-75a3-4ae9-b9df-8e11b8a2ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Afficher la matrice global_obstacle\n",
    "print(global_obstacle)\n",
    "plt.imshow(global_obstacle, cmap='gray')\n",
    "plt.title('Matrice d\\'Obstacles')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "x, y, r = yellow_circles[0] #coordinate of the goal*********************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffc645-cada-46ec-949e-b630f247bfa3",
   "metadata": {},
   "source": [
    "\n",
    "\"Initially, for the setup, it's advantageous to position the camera above the play area. This placement minimizes the need to account for perspective distortions. To accurately determine the robot's position and orientation, at least two distinct markers should be placed on the robot. These markers enable precise tracking and analysis of the robot's movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b1493-4591-41f1-8e1f-c6d43c869c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Detect red and green circles\n",
    "red_circles = detect_color_circle(image, lower_red_bound, upper_red_bound)\n",
    "green_circles = detect_color_circle(image, lower_green_bound, upper_green_bound)\n",
    "yellow_circles = detect_color_circle(image, lower_yellow_bound, upper_yellow_bound)\n",
    "\n",
    "red_circles, green_circles, yellow_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82c685-ef08-4273-b907-37b1a9e68876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming red_circles and green_circles contain the detected circles for each color\n",
    "# For demonstration, let's create dummy circle data\n",
    "# red_circles = [(x1, y1, r1), (x2, y2, r2)]\n",
    "# green_circles = [(x3, y3, r3)]\n",
    "\n",
    "# TODO: Replace the dummy values with your actual circle centers and radii\n",
    "#red_circles = [(50, 50, 30), (150, 50, 30)]  # Dummy values\n",
    "#green_circles = [(100, 150, 30)]  # Dummy values\n",
    "\n",
    "# Calculate the midpoint between the centers of the red circles\n",
    "midpoint = ((red_circles[0][0] + red_circles[1][0]) // 2,\n",
    "            (red_circles[0][1] + red_circles[1][1]) // 2)\n",
    "\n",
    "# Draw a line (and arrow) from the green circle's center to the midpoint\n",
    "cv2.arrowedLine(image,  green_circles[0][:2],midpoint, (0, 255, 0), 20)\n",
    "\n",
    "# Calculate the angle of orientation with respect to the x-axis\n",
    "dx = green_circles[0][0] - midpoint[0]\n",
    "dy = green_circles[0][1] - midpoint[1]\n",
    "angle = math.atan2(dy, dx)\n",
    "angle_degrees = math.degrees(angle)\n",
    "\n",
    "# Display the image with the drawn arrow\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Angle of orientation: {angle_degrees:.2f} degrees')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Return the midpoint and the angle\n",
    "midpoint, angle_degrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67438223-d9b1-418a-8930-f751226a0e25",
   "metadata": {},
   "source": [
    "For the obstacle detection: we used black shapes that we randomly distribute around the board. It is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e368801-d787-4c38-840d-e4f21a95c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#image_path = 'WIN_20231124_15_09_52_Pro.jpg'\n",
    "image = initial_frame #cv2.imread(image_path)\n",
    "image = frame.copy()  # Créer une copie de l'image\n",
    "# Convert to HSV color space\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the lower and upper bounds for the black color\n",
    "lower_black = np.array([0, 0, 0])\n",
    "upper_black = np.array([180, 150, 40])\n",
    "\n",
    "# Create a black color mask\n",
    "mask_black = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(mask_black, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Set a realistic threshold for the area of the contours\n",
    "area_threshold = 2000  # Adjust this threshold according to your needs\n",
    "\n",
    "# Filter the original contours that are larger than the threshold\n",
    "filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > area_threshold]\n",
    "\n",
    "# Perform dilation to increase the size of the black regions\n",
    "kernel_size = 70  # Kernel size can be adjusted to control the amount of dilation\n",
    "kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "mask_dilated = cv2.dilate(mask_black, kernel, iterations=1)\n",
    "\n",
    "# Find contours in the dilated mask\n",
    "dilated_contours, _ = cv2.findContours(mask_dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter the dilated contours that are larger than the threshold\n",
    "filtered_dilated_contours = [cnt for cnt in dilated_contours if cv2.contourArea(cnt) > area_threshold]\n",
    "\n",
    "# Draw the filtered original contours in green\n",
    "for contour in filtered_contours:\n",
    "    cv2.drawContours(image, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "# Draw the filtered dilated contours in red\n",
    "for contour in filtered_dilated_contours:\n",
    "    cv2.drawContours(image, [contour], -1, (0, 0, 255), 2)\n",
    "\n",
    "# Display the image with the drawn contours\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Filtered Original and Dilated Contours')\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f1ea7-1588-4b28-8bbc-6a1fd6180ce2",
   "metadata": {},
   "source": [
    "# Tool functions that help with parameter tuning:\n",
    "<a id=\"Vision-subsection-2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54b1a6-9448-4b46-a8e2-939ef1afe52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detected_circles(image, circles, circle_color):\n",
    "    \"\"\"\n",
    "    Draws the detected circles on the image and plots it.\n",
    "\n",
    "    :param image: The original image.\n",
    "    :param circles: A list of circles with their coordinates and radius.\n",
    "    :param circle_color: The color to use for drawing the circles.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if circles is not None and len(circles) > 0:\n",
    "        for circle in circles:\n",
    "            center = (circle[0], circle[1])  # Circle center\n",
    "            radius = circle[2]  # Circle radius\n",
    "            # Draw the circle's perimeter\n",
    "            cv2.circle(image, center, radius, circle_color, 2)\n",
    "            # Draw the circle's center\n",
    "            cv2.circle(image, center, 2, circle_color, 3)\n",
    "\n",
    "    # Plot the image with detected circles\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05eb0-2409-4b08-8e58-e852199f2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Vérification si la frame a été capturée avec succès\n",
    "if ret:\n",
    "    # Conversion de l'image en RGB pour l'affichage avec Matplotlib\n",
    "    frame_rgb = cv2.cvtColor(initial_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Affichage de l'image\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Erreur lors de la capture de l'image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a142009-f980-44a4-85a6-6302ccfc62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les dimensions de l'image\n",
    "h, w = frame_rgb.shape[:2]\n",
    "\n",
    "# Calculer le nombre total de pixels\n",
    "total_pixels = h * w\n",
    "\n",
    "print(f\"The image is of dimension {w}x{h} (width x hight)\")\n",
    "print(f\"The total number of pixels is : {total_pixels}\")\n",
    "\n",
    "height, width = global_obstacle.shape\n",
    "\n",
    "print(\"Hauteur de la matrice:\", height)\n",
    "print(\"Largeur de la matrice:\", width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd92df-e5c6-432d-ae01-eb5227452df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = initial_frame #cv2.imread('WIN_20231124_15_09_52_Pro.jpg')\n",
    "image = image.copy()\n",
    "# Convert to HSV color space\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the lower and upper bounds for the red color\n",
    "# Note: Adjust these values according to your color calibration\n",
    "\n",
    "\n",
    "# Create a red color mask\n",
    "mask_red = cv2.inRange(hsv, lower_yellow_bound, upper_yellow_bound)\n",
    "\n",
    "# Apply the mask to the image\n",
    "red_only = cv2.bitwise_and(image, image, mask=mask_red)\n",
    "\n",
    "# Convert the result to grayscale\n",
    "gray = cv2.cvtColor(red_only, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Apply Canny edge detection to help with circle detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Detect circles using the Hough Transform\n",
    "circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                           param1=20, param2=15, minRadius=10, maxRadius=50)\n",
    "\n",
    "# If circles are detected, draw them\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "# Plotting the different stages\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(mask_red, cmap='gray')\n",
    "plt.title('Red Mask')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Canny Edges')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Detected Circles')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a355820-2984-4a83-b507-c85b3b551eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "def interactive_mask(lower_h, lower_s, lower_v, upper_h, upper_s, upper_v):\n",
    "    lower_color_bound = np.array([lower_h, lower_s, lower_v])\n",
    "    upper_color_bound = np.array([upper_h, upper_s, upper_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_color_bound, upper_color_bound)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'hsv' is your converted HSV image\n",
    "interactive(interactive_mask, lower_h=(0,255), lower_s=(0,255), lower_v=(0,255),\n",
    "            upper_h=(0,255), upper_s=(0,255), upper_v=(0,255))\n",
    "#lower_red_bound = np.array([120, 70, 120])\n",
    "#upper_red_bound = np.array([255, 255, 255])\n",
    "#lower_green_bound = np.array([60, 120, 100])\n",
    "#upper_green_bound = np.array([100, 255, 255])\n",
    "#lower_black = np.array([0, 0, 0])\n",
    "#upper_black = np.array([180, 255, 50])\n",
    "#lower_yellow_bound = np.array([0, 60, 140])\n",
    "#upper_yellow_bound = np.array([40, 105, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b98467-3505-40c8-9417-8236cdbad250",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = frame #cv2.imread('WIN_20231124_15_09_52_Pro.jpg')\n",
    "red_circles = detect_color_circle(image, lower_red_bound, upper_red_bound)\n",
    "green_circles = detect_color_circle(image, lower_green_bound, upper_green_bound)\n",
    "yellow_circles = detect_color_circle(image, lower_yellow_bound, upper_yellow_bound)\n",
    "\n",
    "red_circles, green_circles, yellow_circles\n",
    "\n",
    "# Assuming red_circles and green_circles contain the detected circles for each color\n",
    "image_copy = image.copy()  # Make a copy to draw on\n",
    "plot_detected_circles(image_copy, red_circles, (200, 0, 255))  # Red color for red circles\n",
    "plot_detected_circles(image_copy, green_circles, (0, 255, 0))  # Green color for green circles\n",
    "plot_detected_circles(image_copy, yellow_circles,(255,255,153))  # yellow color for yellow circles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d89a2-0751-4907-9a38-cee54fc239fd",
   "metadata": {},
   "source": [
    "## 3 Global Navigation\n",
    "<a id=\"global-navigation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a11331",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_x_init = global_obstacle.shape[0]\n",
    "max_val_y_init = global_obstacle.shape[1]\n",
    "\n",
    "reduction_coeff = 20 # tune for speed\n",
    "max_val_x = int(max_val_x_init / reduction_coeff)\n",
    "max_val_y = int(max_val_y_init / reduction_coeff)\n",
    "\n",
    "occupancy_grid = np.zeros((max_val_x, max_val_y), dtype=int)\n",
    "for i in range (max_val_x):\n",
    "    for j in range (max_val_y):\n",
    "        sum_pixels = 0\n",
    "        for k in range (reduction_coeff): # dans le doute on augmente la distance de sécurité avec obstacle\n",
    "            sum_pixels = sum_pixels + binary_matrix[int(i * reduction_coeff - reduction_coeff/2 + k)][int(j * reduction_coeff - reduction_coeff/2 + k)]\n",
    "        if sum_pixels == 0:\n",
    "            occupancy_grid[i][j] = 0\n",
    "        else:\n",
    "            occupancy_grid[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(max_val):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    \n",
    "    major_ticks = np.arange(0, max_val+1, 5)\n",
    "    minor_ticks = np.arange(0, max_val+1, 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([-1,max_val_x])\n",
    "    ax.set_xlim([-1,max_val_y])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf223c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the grid\n",
    "\n",
    "fig, ax = create_empty_plot(max_val_y)\n",
    "\n",
    "cmap = colors.ListedColormap(['white', 'red']) # Select the colors with which to display obstacles and free cells\n",
    "\n",
    "# Displaying the map\n",
    "ax.imshow(occupancy_grid, cmap=cmap)\n",
    "plt.title(\"Map : free cells in white, occupied cells in red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716398d",
   "metadata": {},
   "source": [
    "## A* implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9959a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3865680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_path(cameFrom, current):\n",
    "    \"\"\"\n",
    "    Recurrently reconstructs the path from start node to the current node\n",
    "    :param cameFrom: map (dictionary) containing for each node n the node immediately \n",
    "                     preceding it on the cheapest path from start to n \n",
    "                     currently known.\n",
    "    :param current: current node (x, y)\n",
    "    :return: list of nodes from start to current node\n",
    "    \"\"\"\n",
    "    total_path = [current]\n",
    "    while current in cameFrom.keys():\n",
    "        # Add where the current node came from to the start of the list\n",
    "        total_path.insert(0, cameFrom[current]) \n",
    "        current=cameFrom[current]\n",
    "    return total_path\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\", max_val_x=max_val_x, max_val_y=max_val_y):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node (x, y)\n",
    "    :param goal_m: goal node (x, y)\n",
    "    :param occupancy_grid: the grid map\n",
    "    :param movement: select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # DO NOT EDIT THIS PORTION OF CODE\n",
    "    # -----------------------------------------\n",
    "    \n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "    for point in [start, goal]:\n",
    "        for coord in point:\n",
    "            assert coord>=0 and coord<max_val_y, \"start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A* Algorithm implementation - feel free to change the structure / use another pseudo-code\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    # while there are still elements to investigate\n",
    "    while openSet != []:\n",
    "        \n",
    "        #the node in openSet having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current == goal:\n",
    "            return reconstruct_path(cameFrom, current), closedSet\n",
    "\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        \n",
    "        #for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= occupancy_grid.shape[0]) or (neighbor[1] >= occupancy_grid.shape[1]) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet): \n",
    "                continue\n",
    "                \n",
    "            # d(current,neighbor) is the weight of the edge from current to neighbor\n",
    "            # tentative_gScore is the distance from start to the neighbor through current\n",
    "            tentative_gScore = gScore[current] + deltacost\n",
    "            \n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "                \n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], closedSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b8fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:44:38.966544Z",
     "start_time": "2020-05-08T22:44:37.185492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the start and end goal\n",
    "start = (0,0)\n",
    "goal = (45,60)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# DO NOT EDIT THIS PORTION OF CODE - \n",
    "# EXECUTION AND PLOTTING OF THE ALGORITHM\n",
    "# -----------------------------------------\n",
    "    \n",
    "    \n",
    "# List of all coordinates in the grid\n",
    "x,y = np.mgrid[0:max_val_x:1, 0:max_val_y:1]\n",
    "pos = np.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "\n",
    "# Define the heuristic, here = distance to goal ignoring obstacles\n",
    "h = np.linalg.norm(pos - goal, axis=-1)\n",
    "h = dict(zip(coords, h))\n",
    "\n",
    "# Run the A* algorithm\n",
    "path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"8N\")\n",
    "path = np.array(path).reshape(-1, 2).transpose()\n",
    "visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "\n",
    "path_final = path * reduction_coeff\n",
    "\n",
    "# Displaying the map\n",
    "fig_astar, ax_astar = create_empty_plot(max_val_y)\n",
    "ax_astar.imshow(occupancy_grid, cmap=cmap)\n",
    "print(path_final)\n",
    "# Plot the best path found and the list of visited nodes\n",
    "ax_astar.scatter(visitedNodes[1], visitedNodes[0], marker=\"o\", color = 'orange');\n",
    "ax_astar.plot(path[1], path[0], marker=\"o\", color = 'blue');\n",
    "ax_astar.scatter(start[1], start[0], marker=\"o\", color = 'green', s=200);\n",
    "ax_astar.scatter(goal[1], goal[0], marker=\"o\", color = 'purple', s=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4a839",
   "metadata": {},
   "source": [
    "- blanc : libre\n",
    "- rouge : obstacle\n",
    "- orange : case explorée\n",
    "- bleu : chemin le plus court\n",
    "- vert : départ\n",
    "- violet : arrivée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d0770",
   "metadata": {},
   "source": [
    "Maintenant que nous avons calculé le chemin le plus court, nous appelons des fonctions pour diriger le robot dans la bonne direction. Les données qui sortent de ce fichier sont dans la matrice path_final qui regroupe les coordonées des étapes recalculées à la bonne échelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d53c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eee4515a-9acf-4d55-a716-a1843641eb0f",
   "metadata": {},
   "source": [
    "## 4 Filtering\n",
    "<a id=\"filtering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e109c17-35c3-46cc-899d-fce3f57f88b2",
   "metadata": {},
   "source": [
    "## 5 Local Navigation\n",
    "<a id=\"local-navigation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83967b-ca11-47f2-bd4e-4084c88d5829",
   "metadata": {},
   "source": [
    "## 6 Conclusion\n",
    "<a id=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
